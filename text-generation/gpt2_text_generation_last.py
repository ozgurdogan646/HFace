# -*- coding: utf-8 -*-
"""gpt2-text-generation-last.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15QpenPi-bLOyOMW4kBfjC4J5PrmwNbsK
"""

!pip install transformers

from transformers import TFGPT2LMHeadModel, GPT2Tokenizer
import tensorflow as tf

class TextGeneration():
  def __init__(self):
    self.tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
    self.model  = TFGPT2LMHeadModel.from_pretrained("gpt2")
  
  def encode(self,sentence):
    input_ids = self.tokenizer.encode(sentence, return_tensors="tf")
    return input_ids

  def generate(self):
    tf.random.set_seed(0)
    print("Type 1 for greedy search\nType 2 for beam search\nType 3 for sampling search\nType 4 for top-k sampling")
    choose_method = int(input("Which method do you want to use for text generation"))
    if choose_method == 1:
      sample_output = self.model.generate(
			input_ids,
			do_sample=True,
			max_length=60,
			top_k = 50)
      return self.tokenizer.decode(sample_output[0],skip_special_tokens=True)
    
    elif choose_method==2:
      greedy_output = self.model.generate(input_ids,max_length=50)
      print("Greedy search result:")
      return self.tokenizer.decode(greedy_output[0], skip_special_tokens = True)

textg = TextGeneration()
input_ids = textg.encode("I was walking on the street.")

output = textg.generate()
print(output)

